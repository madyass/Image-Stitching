import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))


import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import json
import cv2
from functions.functions import  align_and_merge_images





img1 = cv2.imread("dataset/grid/image1.png") 
img2 = cv2.imread("dataset/grid/image2.png")


with open("dataset/grid/correspondences.json" , 'r') as f:
    data = json.load(f)


src = np.array([item["img2_xy"] for item in data])  # transformed image
dst = np.array([item["img1_xy"] for item in data])  # original image

print("Source points:\n", src)
print("Destination points:\n", dst)


plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
plt.title("img1")

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))
plt.title("img2")
plt.show()


R , t = umeyama_alignment(src , dst)
print("Rotation Matrix :\n" , R)
print("Transtion Matrix :\n" , t)


N = np.hstack([R , t.reshape(-1 ,1)])
h , w = img1.shape[:2]
img2_transformed = cv2.warpAffine(img2, N, (w, h))


plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
plt.title("img1")

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(img2_transformed, cv2.COLOR_BGR2RGB))
plt.title("rotated")
plt.show()


result = align_and_merge_images(img1, img2, src, dst)

plt.figure(figsize=(12, 6))
plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))





with open("dataset/mountain/correspondences.json" , 'r') as f:
    data = json.load(f)


src = np.array([item["img2_xy"] for item in data])  # transformed image
dst = np.array([item["img1_xy"] for item in data])  # original image

print("Source points:\n", src)
print("Destination points:\n", dst)


img1 = cv2.imread("dataset/mountain/image1.png") 
img2 = cv2.imread("dataset/mountain/image2.png")


plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
plt.title("img1")

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))
plt.title("img2")
plt.show()


R , t = umeyama_alignment(src , dst)
print("Rotation Matrix :\n" , R)
print("Transtion Matrix :\n" , t)


N = np.hstack([R , t.reshape(-1 ,1)])
h , w = img1.shape[:2]
img2_transformed = cv2.warpAffine(img2, N, (w, h))


plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
plt.title("img1")

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(img2_transformed, cv2.COLOR_BGR2RGB))
plt.title("rotated img")
plt.show()


result = align_and_merge_images(img1, img2, src, dst)

plt.figure(figsize=(12, 6))
plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))





with open("dataset/pikachu/correspondences.json" , 'r') as f:
    data = json.load(f)


src = np.array([item["img2_xy"] for item in data])  # transformed image
dst = np.array([item["img1_xy"] for item in data])  # original image

print("Source points:\n", src)
print("Destination points:\n", dst)


img1 = cv2.imread("dataset/pikachu/image1.png") 
img2 = cv2.imread("dataset/pikachu/image2.png")


plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
plt.title("img1")

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))
plt.title("img2")
plt.show()


R , t = umeyama_alignment(src , dst)
print("Rotation Matrix :\n" , R)
print("Transtion Matrix :\n" , t)


N = np.hstack([R , t.reshape(-1 ,1)])
h , w = img1.shape[:2]
img2_transformed = cv2.warpAffine(img2, N, (w, h))


plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
plt.title("img1")

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(img2_transformed, cv2.COLOR_BGR2RGB))
plt.title("rotated img")
plt.show()


result = align_and_merge_images(img1, img2, src, dst)

plt.figure(figsize=(12, 6))
plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
